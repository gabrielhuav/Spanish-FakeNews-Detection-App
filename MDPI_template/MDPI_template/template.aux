\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\citation{bondielli2019survey}
\citation{posadas2019detection,acosta2019construccion}
\citation{hurtado2024calibracion}
\citation{vaswani2017attention}
\citation{hu2022deep,garcia2024fake}
\providecommand \oddpage@label [2]{}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{posadas2019detection,acosta2019construccion,blanco2024enhancing,tretiakov2022detection}
\citation{tsai2023stylometric,posadas2019detection}
\citation{thota2018fake,garcia2024fake}
\citation{blanco2024enhancing,martinez2021fake}
\citation{yildirim2023novel,hurtado2024calibracion,padilla2024medicobert}
\citation{posadas2019detection,acosta2019construccion,blanco2024enhancing}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of Methodological Paradigms in Fake News Detection.}}{2}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:methodological_paradigms}{{1}{2}{Comparison of Methodological Paradigms in Fake News Detection}{table.caption.1}{}}
\newlabel{tab:methodological_paradigms@cref}{{[table][1][]1}{[1][2][]2}}
\citation{martinez2021fake}
\citation{padilla2024medicobert}
\citation{hurtado2024calibracion}
\citation{posadas2019detection}
\citation{acosta2019construccion}
\citation{blanco2024enhancing}
\citation{martinez2021fake}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Spanish Language Resources for Fake News Detection}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Hyperparameter Optimization in Transformers and Metaheuristics}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Deployment of NLP Models}{3}{subsection.2.3}\protected@file@percent }
\citation{yildirim2023novel}
\citation{thota2018fake}
\citation{garcia2024fake}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of key related works (Part 1): Corpus Creation \& Transformer Application.}}{4}{table.caption.2}\protected@file@percent }
\newlabel{tab:related_work_summary1}{{2}{4}{Summary of key related works (Part 1): Corpus Creation \& Transformer Application}{table.caption.2}{}}
\newlabel{tab:related_work_summary1@cref}{{[table][2][]2}{[1][3][]4}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Summary of key related works (Part 2): Metaheuristic and Classical Approaches.}}{4}{table.caption.3}\protected@file@percent }
\newlabel{tab:related_work_summary2}{{3}{4}{Summary of key related works (Part 2): Metaheuristic and Classical Approaches}{table.caption.3}{}}
\newlabel{tab:related_work_summary2@cref}{{[table][3][]3}{[1][4][]4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Materials and Methods}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Proposed Methodology Overview}{4}{subsection.3.1}\protected@file@percent }
\citation{posadas2019detection}
\citation{acosta2019construccion}
\citation{tretiakov2022detection}
\citation{blanco2024enhancing}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of the proposed research methodology, illustrating the evolutionary path from data unification to the comparative evaluation of classical and transformer-based approaches, culminating in a deployed application.}}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:metodologia_general}{{1}{5}{Overview of the proposed research methodology, illustrating the evolutionary path from data unification to the comparative evaluation of classical and transformer-based approaches, culminating in a deployed application}{figure.caption.4}{}}
\newlabel{fig:metodologia_general@cref}{{[figure][1][]1}{[1][4][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Building the Dataset}{5}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Collecting Academic Datasets}{5}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Exhaustive comparison of the characteristics of the corpora used in the construction of the unified dataset.}}{5}{table.caption.5}\protected@file@percent }
\newlabel{tab:comparacion_exhaustiva_corpus}{{4}{5}{Exhaustive comparison of the characteristics of the corpora used in the construction of the unified dataset}{table.caption.5}{}}
\newlabel{tab:comparacion_exhaustiva_corpus@cref}{{[table][4][]4}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Cleaning and Standardizing}{5}{subsubsection.3.2.2}\protected@file@percent }
\citation{aragon2020overview}
\citation{hurtado2024calibracion}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Dealing with Unbalanced Data}{6}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visual representation of the corpus balancing process. The initial imbalanced distribution (left) was corrected by strategically adding 9,000 FAKE articles via web scraping, resulting in a nearly 50/50 final distribution (right).}}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:corpus_balance}{{2}{6}{Visual representation of the corpus balancing process. The initial imbalanced distribution (left) was corrected by strategically adding 9,000 FAKE articles via web scraping, resulting in a nearly 50/50 final distribution (right)}{figure.caption.6}{}}
\newlabel{fig:corpus_balance@cref}{{[figure][2][]2}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Traditional Machine Learning Experiments}{6}{subsection.3.3}\protected@file@percent }
\citation{devlin2018bert}
\citation{sanh2019distilbert}
\citation{jiao2019tinybert}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Deep Learning with Transformers}{7}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Picking the Right Model}{7}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Comparison of optimized BERT models for the classification task.}}{7}{table.caption.7}\protected@file@percent }
\newlabel{tab:comparacion_modelos_bert}{{5}{7}{Comparison of optimized BERT models for the classification task}{table.caption.7}{}}
\newlabel{tab:comparacion_modelos_bert@cref}{{[table][5][]5}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Fine-tuning the Model Parameters}{7}{subsubsection.3.4.2}\protected@file@percent }
\newlabel{fig:overfitting_example}{{3\normalfont  (\textbf  {a})}{7}{Subfigure 3\protect \normalfont  (\protect \textbf  {a})}{subfigure.3.1}{}}
\newlabel{sub@fig:overfitting_example}{{(\normalfont  (\textbf  {a}))}{\normalfont  (\textbf  {a})}{Subfigure 3\normalfont  (\textbf  {a})\relax }{subfigure.3.1}{}}
\newlabel{fig:overfitting_example@cref}{{[subfigure][1][3]3\normalfont  (\textbf  {a})}{[1][7][]7}}
\newlabel{fig:underfitting_example}{{3\normalfont  (\textbf  {b})}{7}{Subfigure 3\protect \normalfont  (\protect \textbf  {b})}{subfigure.3.2}{}}
\newlabel{sub@fig:underfitting_example}{{(\normalfont  (\textbf  {b}))}{\normalfont  (\textbf  {b})}{Subfigure 3\normalfont  (\textbf  {b})\relax }{subfigure.3.2}{}}
\newlabel{fig:underfitting_example@cref}{{[subfigure][2][3]3\normalfont  (\textbf  {b})}{[1][7][]7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visual examples of overfitting, where training and validation curves diverge, and underfitting, where both fail to converge.}}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:overfitting_underfitting_examples}{{3}{7}{Visual examples of overfitting, where training and validation curves diverge, and underfitting, where both fail to converge}{figure.caption.8}{}}
\newlabel{fig:overfitting_underfitting_examples@cref}{{[figure][3][]3}{[1][7][]7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {a}))}{\ignorespaces {Example of Overfitting}}}{7}{subfigure.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {b}))}{\ignorespaces {Example of Underfitting}}}{7}{subfigure.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Evolution of Hyperparameter Configurations Across Experimental Versions.}}{8}{table.caption.9}\protected@file@percent }
\newlabel{tab:hyperparam_evolution}{{6}{8}{Evolution of Hyperparameter Configurations Across Experimental Versions}{table.caption.9}{}}
\newlabel{tab:hyperparam_evolution@cref}{{[table][6][]6}{[1][7][]8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Training Configuration Results}{8}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Web Application Implementation}{8}{subsection.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces System architecture of the deployed web application, showing the static components and their dependencies.}}{9}{figure.caption.10}\protected@file@percent }
\newlabel{fig:system_components}{{4}{9}{System architecture of the deployed web application, showing the static components and their dependencies}{figure.caption.10}{}}
\newlabel{fig:system_components@cref}{{[figure][4][]4}{[1][8][]9}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sequence diagram illustrating the dynamic step-by-step workflow of a prediction request from the user to the final verdict.}}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:system_sequence}{{5}{9}{Sequence diagram illustrating the dynamic step-by-step workflow of a prediction request from the user to the final verdict}{figure.caption.11}{}}
\newlabel{fig:system_sequence@cref}{{[figure][5][]5}{[1][9][]9}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{9}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Evaluation Metrics}{9}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Performance of the Metaheuristic Approach}{10}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Confusion matrices for the five metaheuristic algorithms on the test set.}}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:metaheuristic_confusion_matrices}{{6}{11}{Confusion matrices for the five metaheuristic algorithms on the test set}{figure.caption.12}{}}
\newlabel{fig:metaheuristic_confusion_matrices@cref}{{[figure][6][]6}{[1][10][]11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {a}))}{\ignorespaces {GA Confusion Matrix}}}{11}{subfigure.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {b}))}{\ignorespaces {VNS Confusion Matrix}}}{11}{subfigure.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {c}))}{\ignorespaces {SS Confusion Matrix}}}{11}{subfigure.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {d}))}{\ignorespaces {MSA Confusion Matrix}}}{11}{subfigure.6.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {e}))}{\ignorespaces {PSO Confusion Matrix}}}{11}{subfigure.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Performance of the Transformer Model}{11}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Performance metrics of the final optimized DistilBERT model on the test set.}}{11}{table.caption.13}\protected@file@percent }
\newlabel{tab:final_metrics}{{7}{11}{Performance metrics of the final optimized DistilBERT model on the test set}{table.caption.13}{}}
\newlabel{tab:final_metrics@cref}{{[table][7][]7}{[1][11][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Confusion matrix for the final DistilBERT model on the test set.}}{11}{figure.caption.14}\protected@file@percent }
\newlabel{fig:distilbert_confusion_matrix}{{7}{11}{Confusion matrix for the final DistilBERT model on the test set}{figure.caption.14}{}}
\newlabel{fig:distilbert_confusion_matrix@cref}{{[figure][7][]7}{[1][11][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Final Comparative Analysis: Metaheuristics vs. Transformer}{12}{subsection.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Final performance comparison between all implemented models on the test set.}}{12}{table.caption.15}\protected@file@percent }
\newlabel{tab:final_comparison_all_models}{{8}{12}{Final performance comparison between all implemented models on the test set}{table.caption.15}{}}
\newlabel{tab:final_comparison_all_models@cref}{{[table][8][]8}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Overfitting Control Analysis}{12}{subsection.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Evolution of accuracy and loss during the training of the final model (V7). The blue and red lines represent the training and validation metrics, respectively. The gold star marks the optimal epoch (13), where validation loss was minimal and the generalization gap was controlled, just before the onset of overfitting.}}{12}{figure.caption.16}\protected@file@percent }
\newlabel{fig:training_curves}{{8}{12}{Evolution of accuracy and loss during the training of the final model (V7). The blue and red lines represent the training and validation metrics, respectively. The gold star marks the optimal epoch (13), where validation loss was minimal and the generalization gap was controlled, just before the onset of overfitting}{figure.caption.16}{}}
\newlabel{fig:training_curves@cref}{{[figure][8][]8}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Real-World Application Performance}{12}{subsection.4.6}\protected@file@percent }
\newlabel{fig:sub1}{{9\normalfont  (\textbf  {a})}{13}{Subfigure 9\protect \normalfont  (\protect \textbf  {a})}{subfigure.9.1}{}}
\newlabel{sub@fig:sub1}{{(\normalfont  (\textbf  {a}))}{\normalfont  (\textbf  {a})}{Subfigure 9\normalfont  (\textbf  {a})\relax }{subfigure.9.1}{}}
\newlabel{fig:sub1@cref}{{[subfigure][1][9]9\normalfont  (\textbf  {a})}{[1][12][]13}}
\newlabel{fig:sub2}{{9\normalfont  (\textbf  {b})}{13}{Subfigure 9\protect \normalfont  (\protect \textbf  {b})}{subfigure.9.2}{}}
\newlabel{sub@fig:sub2}{{(\normalfont  (\textbf  {b}))}{\normalfont  (\textbf  {b})}{Subfigure 9\normalfont  (\textbf  {b})\relax }{subfigure.9.2}{}}
\newlabel{fig:sub2@cref}{{[subfigure][2][9]9\normalfont  (\textbf  {b})}{[1][12][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Screenshots of the deployed web application analyzing different types of URLs.}}{13}{figure.caption.17}\protected@file@percent }
\newlabel{fig:app_screenshots}{{9}{13}{Screenshots of the deployed web application analyzing different types of URLs}{figure.caption.17}{}}
\newlabel{fig:app_screenshots@cref}{{[figure][9][]9}{[1][12][]13}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {a}))}{\ignorespaces {Correctly identifying a real news article with 93.59\% confidence.}}}{13}{subfigure.9.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {b}))}{\ignorespaces {Successfully identifying a misleading fake news piece with 94.31\% confidence.}}}{13}{subfigure.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{13}{section.5}\protected@file@percent }
\bibcite{bondielli2019survey}{{1}{}{{}}{{}}}
\bibcite{posadas2019detection}{{2}{}{{}}{{}}}
\bibcite{acosta2019construccion}{{3}{}{{}}{{}}}
\bibcite{hurtado2024calibracion}{{4}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{14}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}References}{14}{section.7}\protected@file@percent }
\bibcite{vaswani2017attention}{{5}{}{{}}{{}}}
\bibcite{hu2022deep}{{6}{}{{}}{{}}}
\bibcite{blanco2024enhancing}{{7}{}{{}}{{}}}
\bibcite{tretiakov2022detection}{{8}{}{{}}{{}}}
\bibcite{sanh2019distilbert}{{9}{}{{}}{{}}}
\bibcite{gomez2021overview}{{10}{}{{}}{{}}}
\bibcite{devlin2018bert}{{11}{}{{}}{{}}}
\bibcite{thota2018fake}{{12}{}{{}}{{}}}
\bibcite{aragon2020overview}{{13}{}{{}}{{}}}
\bibcite{yildirim2023novel}{{14}{}{{}}{{}}}
\bibcite{tsai2023stylometric}{{15}{}{{}}{{}}}
\bibcite{martinez2021fake}{{16}{}{{}}{{}}}
\bibcite{jiao2019tinybert}{{17}{}{{}}{{}}}
\bibcite{garcia2024fake}{{18}{}{{}}{{}}}
\bibcite{padilla2024medicobert}{{19}{}{{}}{{}}}
\newlabel{LastPage}{{}{15}{}{page.15}{}}
\xdef\lastpage@lastpage{15}
\xdef\lastpage@lastpageHy{15}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{15}
