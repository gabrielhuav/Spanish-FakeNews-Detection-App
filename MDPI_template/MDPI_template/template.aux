\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\citation{bondielli2019survey}
\citation{higdon2022agree,higdon2025constructive}
\citation{tsfati2020causes}
\citation{shu2017fake,ali2022fake}
\providecommand \oddpage@label [2]{}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{nasir2021fake,zhou2020survey}
\citation{devlin2018bert}
\citation{vaswani2017attention}
\citation{singh2024comprehensive,alghamdi2024comprehensive}
\citation{kaliyar2021fakebert}
\citation{choudhry2024emotion}
\citation{nasir2021fake}
\citation{singh2024comprehensive}
\citation{alghamdi2024comprehensive}
\citation{kaliyar2021fakebert}
\citation{choudhry2024emotion}
\citation{nasir2021fake}
\citation{tsfati2020causes}
\citation{higdon2022agree,higdon2025constructive}
\citation{hu2022deep}
\citation{kaliyar2021fakebert}
\citation{hu2022deep}
\citation{singh2024comprehensive,alghamdi2024comprehensive}
\citation{posadas2019detection}
\citation{ali2022fake}
\citation{singh2024comprehensive}
\citation{blanco2024enhancing,martinez2021fake}
\citation{ali2022fake}
\citation{bondielli2019survey}
\citation{posadas2019detection,acosta2019construccion,blanco2024enhancing,tretiakov2022detection}
\citation{singh2024comprehensive,alghamdi2024comprehensive}
\citation{ali2022fake}
\citation{higdon2022agree}
\citation{higdon2025constructive}
\citation{tsfati2020causes}
\citation{shu2017fake}
\citation{ali2022fake}
\citation{thota2018fake}
\citation{nasir2021fake}
\citation{zhou2020survey}
\citation{singh2024comprehensive}
\citation{alghamdi2024comprehensive}
\citation{kaliyar2021fakebert}
\citation{choudhry2024emotion}
\citation{posadas2019detection,acosta2019construccion,blanco2024enhancing}
\citation{martinez2021fake}
\citation{padilla2024medicobert}
\citation{shu2017fake}
\@writefile{toc}{\contentsline {section}{\numberline {2}Evolution of Fake News Detection Paradigms}{4}{section.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of Methodological Paradigms in Fake News Detection.}}{4}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:methodological_paradigms}{{1}{4}{Comparison of Methodological Paradigms in Fake News Detection}{table.caption.1}{}}
\newlabel{tab:methodological_paradigms@cref}{{[table][1][]1}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Spanish Language Resources for Fake News Detection}{4}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Hyperparameter Optimization in Transformers and Metaheuristics}{4}{subsection.2.2}\protected@file@percent }
\citation{posadas2019detection}
\citation{kaliyar2021fakebert}
\citation{blanco2024enhancing}
\citation{martinez2021fake}
\citation{yildirim2023novel}
\citation{thota2018fake}
\citation{garcia2024fake}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Deployment of NLP Models}{5}{subsection.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of key related works (Part 1): Corpus Creation \& Transformer Application.}}{5}{table.caption.2}\protected@file@percent }
\newlabel{tab:related_work_summary1}{{2}{5}{Summary of key related works (Part 1): Corpus Creation \& Transformer Application}{table.caption.2}{}}
\newlabel{tab:related_work_summary1@cref}{{[table][2][]2}{[1][5][]5}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Summary of key related works (Part 2): Metaheuristic and Classical Approaches.}}{5}{table.caption.3}\protected@file@percent }
\newlabel{tab:related_work_summary2}{{3}{5}{Summary of key related works (Part 2): Metaheuristic and Classical Approaches}{table.caption.3}{}}
\newlabel{tab:related_work_summary2@cref}{{[table][3][]3}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Recent Advances and Comprehensive Surveys (2020-2025)}{5}{subsection.2.4}\protected@file@percent }
\citation{singh2024comprehensive}
\citation{alghamdi2024comprehensive}
\citation{choudhry2024emotion}
\citation{nasir2021fake}
\citation{tsfati2020causes}
\citation{higdon2022agree}
\citation{higdon2025constructive}
\citation{ali2022fake}
\citation{singh2024comprehensive}
\citation{alghamdi2024comprehensive}
\@writefile{toc}{\contentsline {section}{\numberline {3}Materials and Methods}{6}{section.3}\protected@file@percent }
\citation{posadas2019detection}
\citation{acosta2019construccion}
\citation{tretiakov2022detection}
\citation{blanco2024enhancing}
\citation{aragon2020overview}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of the proposed research methodology (Part 1/3): Data Unification and Processing.}}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:metodologia_general_p1}{{1}{7}{Overview of the proposed research methodology (Part 1/3): Data Unification and Processing}{figure.caption.4}{}}
\newlabel{fig:metodologia_general_p1@cref}{{[figure][1][]1}{[1][6][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Acquisition and Processing}{7}{subsection.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Exhaustive comparison of the characteristics of the corpora used in the construction of the unified dataset.}}{7}{table.caption.5}\protected@file@percent }
\newlabel{tab:comparacion_exhaustiva_corpus}{{4}{7}{Exhaustive comparison of the characteristics of the corpora used in the construction of the unified dataset}{table.caption.5}{}}
\newlabel{tab:comparacion_exhaustiva_corpus@cref}{{[table][4][]4}{[1][7][]7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visual representation of the corpus balancing process. The initial imbalanced distribution (left) was corrected by strategically adding 9,000 FAKE articles via web scraping, resulting in a nearly 50/50 final distribution (right). Source: Authors' own elaboration based on study data.}}{8}{figure.caption.6}\protected@file@percent }
\newlabel{fig:corpus_balance}{{2}{8}{Visual representation of the corpus balancing process. The initial imbalanced distribution (left) was corrected by strategically adding 9,000 FAKE articles via web scraping, resulting in a nearly 50/50 final distribution (right). Source: Authors' own elaboration based on study data}{figure.caption.6}{}}
\newlabel{fig:corpus_balance@cref}{{[figure][2][]2}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model Development and Optimization}{8}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Data Partitioning and Generalization Strategy}{8}{subsubsection.3.2.1}\protected@file@percent }
\citation{shu2017fake}
\citation{sanh2019distilbert}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Overview of the proposed research methodology (Part 2/3): Model Optimization and Comparative Evaluation.}}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:metodologia_general_p2}{{3}{9}{Overview of the proposed research methodology (Part 2/3): Model Optimization and Comparative Evaluation}{figure.caption.7}{}}
\newlabel{fig:metodologia_general_p2@cref}{{[figure][3][]3}{[1][8][]9}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Comparison of optimized BERT models for the classification task.}}{10}{table.caption.8}\protected@file@percent }
\newlabel{tab:comparacion_modelos_bert}{{5}{10}{Comparison of optimized BERT models for the classification task}{table.caption.8}{}}
\newlabel{tab:comparacion_modelos_bert@cref}{{[table][5][]5}{[1][10][]10}}
\newlabel{fig:overfitting_example}{{4\normalfont  (\textbf  {a})}{10}{Subfigure 4\protect \normalfont  (\protect \textbf  {a})}{subfigure.4.1}{}}
\newlabel{sub@fig:overfitting_example}{{(\normalfont  (\textbf  {a}))}{\normalfont  (\textbf  {a})}{Subfigure 4\normalfont  (\textbf  {a})\relax }{subfigure.4.1}{}}
\newlabel{fig:overfitting_example@cref}{{[subfigure][1][4]4\normalfont  (\textbf  {a})}{[1][10][]10}}
\newlabel{fig:underfitting_example}{{4\normalfont  (\textbf  {b})}{10}{Subfigure 4\protect \normalfont  (\protect \textbf  {b})}{subfigure.4.2}{}}
\newlabel{sub@fig:underfitting_example}{{(\normalfont  (\textbf  {b}))}{\normalfont  (\textbf  {b})}{Subfigure 4\normalfont  (\textbf  {b})\relax }{subfigure.4.2}{}}
\newlabel{fig:underfitting_example@cref}{{[subfigure][2][4]4\normalfont  (\textbf  {b})}{[1][10][]10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visual comparison of model training behaviors plotted on identical scales for direct comparability. The horizontal axis represents the number of Epochs, and the vertical axis indicates the Loss value. (a) Illustrates \textbf  {overfitting}, where the model memorizes the training data (blue line decreases) but fails to generalize to new data (red validation line increases). (b) Illustrates \textbf  {underfitting}, characterized by the inability of the model to capture underlying patterns, resulting in high loss values for both curves.}}{10}{figure.caption.9}\protected@file@percent }
\newlabel{fig:overfitting_underfitting_examples}{{4}{10}{Visual comparison of model training behaviors plotted on identical scales for direct comparability. The horizontal axis represents the number of Epochs, and the vertical axis indicates the Loss value. (a) Illustrates \textbf {overfitting}, where the model memorizes the training data (blue line decreases) but fails to generalize to new data (red validation line increases). (b) Illustrates \textbf {underfitting}, characterized by the inability of the model to capture underlying patterns, resulting in high loss values for both curves}{figure.caption.9}{}}
\newlabel{fig:overfitting_underfitting_examples@cref}{{[figure][4][]4}{[1][10][]10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {a}))}{\ignorespaces {Overfitting scenario: Validation loss diverges while training loss decreases.}}}{10}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {b}))}{\ignorespaces {Underfitting scenario: Both training and validation losses remain high without convergence.}}}{10}{subfigure.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Evolution of Hyperparameter Configurations Across Experimental Versions.}}{10}{table.caption.10}\protected@file@percent }
\newlabel{tab:hyperparam_evolution}{{6}{10}{Evolution of Hyperparameter Configurations Across Experimental Versions}{table.caption.10}{}}
\newlabel{tab:hyperparam_evolution@cref}{{[table][6][]6}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Real-World Application Deployment}{11}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Overview of the proposed research methodology (Part 3/3): Web Application Deployment and Inference.}}{11}{figure.caption.11}\protected@file@percent }
\newlabel{fig:metodologia_general_p3}{{5}{11}{Overview of the proposed research methodology (Part 3/3): Web Application Deployment and Inference}{figure.caption.11}{}}
\newlabel{fig:metodologia_general_p3@cref}{{[figure][5][]5}{[1][11][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces System architecture of the deployed web application, showing the static components and their dependencies.}}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:system_components}{{6}{11}{System architecture of the deployed web application, showing the static components and their dependencies}{figure.caption.12}{}}
\newlabel{fig:system_components@cref}{{[figure][6][]6}{[1][11][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Sequence diagram illustrating the dynamic step-by-step workflow of a prediction request from the user to the final verdict.}}{12}{figure.caption.13}\protected@file@percent }
\newlabel{fig:system_sequence}{{7}{12}{Sequence diagram illustrating the dynamic step-by-step workflow of a prediction request from the user to the final verdict}{figure.caption.13}{}}
\newlabel{fig:system_sequence@cref}{{[figure][7][]7}{[1][12][]12}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{13}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Evaluation Metrics}{13}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Performance of the Metaheuristic Approach}{13}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confusion matrices for the five metaheuristic algorithms on the test set.}}{14}{figure.caption.14}\protected@file@percent }
\newlabel{fig:metaheuristic_confusion_matrices}{{8}{14}{Confusion matrices for the five metaheuristic algorithms on the test set}{figure.caption.14}{}}
\newlabel{fig:metaheuristic_confusion_matrices@cref}{{[figure][8][]8}{[1][13][]14}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {a}))}{\ignorespaces {GA Confusion Matrix}}}{14}{subfigure.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {b}))}{\ignorespaces {VNS Confusion Matrix}}}{14}{subfigure.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {c}))}{\ignorespaces {SS Confusion Matrix}}}{14}{subfigure.8.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {d}))}{\ignorespaces {MSA Confusion Matrix}}}{14}{subfigure.8.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {e}))}{\ignorespaces {PSO Confusion Matrix}}}{14}{subfigure.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Performance of the Transformer Model}{15}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Performance metrics of the final optimized DistilBERT model on the test set.}}{15}{table.caption.15}\protected@file@percent }
\newlabel{tab:final_metrics}{{7}{15}{Performance metrics of the final optimized DistilBERT model on the test set}{table.caption.15}{}}
\newlabel{tab:final_metrics@cref}{{[table][7][]7}{[1][15][]15}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Confusion matrix for the final DistilBERT model on the test set.}}{15}{figure.caption.16}\protected@file@percent }
\newlabel{fig:distilbert_confusion_matrix}{{9}{15}{Confusion matrix for the final DistilBERT model on the test set}{figure.caption.16}{}}
\newlabel{fig:distilbert_confusion_matrix@cref}{{[figure][9][]9}{[1][15][]15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Final Comparative Analysis: Metaheuristics vs. Transformer}{16}{subsection.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Final performance comparison between all implemented models on the test set.}}{16}{table.caption.17}\protected@file@percent }
\newlabel{tab:final_comparison_all_models}{{8}{16}{Final performance comparison between all implemented models on the test set}{table.caption.17}{}}
\newlabel{tab:final_comparison_all_models@cref}{{[table][8][]8}{[1][16][]16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Overfitting Control Analysis}{16}{subsection.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Evolution of performance metrics during the fine-tuning of the final model (V11). The x-axis represents the training epochs, while the y-axes represent Loss (left) and Accuracy (right). The blue lines denote training performance, and the red lines denote validation performance. The gold star identifies the optimal checkpoint at Epoch 13, where the generalization gap (0.058) was minimized before the onset of overfitting.}}{16}{figure.caption.18}\protected@file@percent }
\newlabel{fig:training_curves}{{10}{16}{Evolution of performance metrics during the fine-tuning of the final model (V11). The x-axis represents the training epochs, while the y-axes represent Loss (left) and Accuracy (right). The blue lines denote training performance, and the red lines denote validation performance. The gold star identifies the optimal checkpoint at Epoch 13, where the generalization gap (0.058) was minimized before the onset of overfitting}{figure.caption.18}{}}
\newlabel{fig:training_curves@cref}{{[figure][10][]10}{[1][16][]16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Real-World Application Performance}{17}{subsection.4.6}\protected@file@percent }
\newlabel{fig:sub1}{{11\normalfont  (\textbf  {a})}{17}{Subfigure 11\protect \normalfont  (\protect \textbf  {a})}{subfigure.11.1}{}}
\newlabel{sub@fig:sub1}{{(\normalfont  (\textbf  {a}))}{\normalfont  (\textbf  {a})}{Subfigure 11\normalfont  (\textbf  {a})\relax }{subfigure.11.1}{}}
\newlabel{fig:sub1@cref}{{[subfigure][1][11]11\normalfont  (\textbf  {a})}{[1][17][]17}}
\newlabel{fig:sub2}{{11\normalfont  (\textbf  {b})}{17}{Subfigure 11\protect \normalfont  (\protect \textbf  {b})}{subfigure.11.2}{}}
\newlabel{sub@fig:sub2}{{(\normalfont  (\textbf  {b}))}{\normalfont  (\textbf  {b})}{Subfigure 11\normalfont  (\textbf  {b})\relax }{subfigure.11.2}{}}
\newlabel{fig:sub2@cref}{{[subfigure][2][11]11\normalfont  (\textbf  {b})}{[1][17][]17}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Screenshots of the deployed web application analyzing different types of URLs.}}{17}{figure.caption.19}\protected@file@percent }
\newlabel{fig:app_screenshots}{{11}{17}{Screenshots of the deployed web application analyzing different types of URLs}{figure.caption.19}{}}
\newlabel{fig:app_screenshots@cref}{{[figure][11][]11}{[1][17][]17}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {a}))}{\ignorespaces {Correctly identifying a real news article with 93.59\% confidence.}}}{17}{subfigure.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(\normalfont (\textbf {b}))}{\ignorespaces {Successfully identifying a misleading fake news piece with 94.31\% confidence.}}}{17}{subfigure.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{17}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{18}{section.6}\protected@file@percent }
\bibcite{bondielli2019survey}{{1}{}{{}}{{}}}
\bibcite{shu2017fake}{{2}{}{{}}{{}}}
\bibcite{zhou2020survey}{{3}{}{{}}{{}}}
\bibcite{kaliyar2021fakebert}{{4}{}{{}}{{}}}
\bibcite{hu2022deep}{{5}{}{{}}{{}}}
\bibcite{posadas2019detection}{{6}{}{{}}{{}}}
\bibcite{acosta2019construccion}{{7}{}{{}}{{}}}
\bibcite{blanco2024enhancing}{{8}{}{{}}{{}}}
\bibcite{tretiakov2022detection}{{9}{}{{}}{{}}}
\bibcite{tsai2023stylometric}{{10}{}{{}}{{}}}
\bibcite{thota2018fake}{{11}{}{{}}{{}}}
\bibcite{garcia2024fake}{{12}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {7}References}{19}{section.7}\protected@file@percent }
\bibcite{martinez2021fake}{{13}{}{{}}{{}}}
\bibcite{gomez2021overview}{{14}{}{{}}{{}}}
\bibcite{yildirim2023novel}{{15}{}{{}}{{}}}
\bibcite{padilla2024medicobert}{{16}{}{{}}{{}}}
\bibcite{aragon2020overview}{{17}{}{{}}{{}}}
\bibcite{vaswani2017attention}{{18}{}{{}}{{}}}
\bibcite{devlin2018bert}{{19}{}{{}}{{}}}
\bibcite{sanh2019distilbert}{{20}{}{{}}{{}}}
\bibcite{jiao2019tinybert}{{21}{}{{}}{{}}}
\bibcite{higdon2025constructive}{{22}{}{{}}{{}}}
\bibcite{singh2024comprehensive}{{23}{}{{}}{{}}}
\bibcite{choudhry2024emotion}{{24}{}{{}}{{}}}
\bibcite{alghamdi2024comprehensive}{{25}{}{{}}{{}}}
\bibcite{higdon2022agree}{{26}{}{{}}{{}}}
\bibcite{ali2022fake}{{27}{}{{}}{{}}}
\bibcite{nasir2021fake}{{28}{}{{}}{{}}}
\bibcite{tsfati2020causes}{{29}{}{{}}{{}}}
\newlabel{LastPage}{{}{20}{}{page.20}{}}
\xdef\lastpage@lastpage{20}
\xdef\lastpage@lastpageHy{20}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{20}
